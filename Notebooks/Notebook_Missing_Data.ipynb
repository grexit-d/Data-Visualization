{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6E_d6ypElNC"
   },
   "source": [
    "# Handling Missing Values: Comprehensive Notebook\n",
    "\n",
    "This Python notebook provides an in-depth exploration of techniques to handle missing data, a crucial aspect of data preprocessing in machine learning and data analysis. By the end of this notebook, you will:\n",
    "- Understand the importance of addressing missing values.\n",
    "- Learn various techniques to visualize and handle missing data.\n",
    "- Gain hands-on experience with real-world examples.\n",
    "\n",
    "Let's dive in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qby6c-iIEoJF"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Step 1: Importing necessary libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "# Ensure plots are displayed inline in Jupyter Notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rTvaALG-Epi9"
   },
   "outputs": [],
   "source": [
    "# Step 2: Setting up a sample dataset with missing values\n",
    "np.random.seed(42)\n",
    "data = pd.DataFrame({\n",
    "    'Feature_1': np.random.choice([1, 2, np.nan], size=100, p=[0.45, 0.45, 0.1]),\n",
    "    'Feature_2': np.random.choice([3, 4, np.nan], size=100, p=[0.76, 0.20, 0.04]),\n",
    "    'Feature_3': np.random.choice([5, np.nan], size=100, p=[0.2, 0.8]),\n",
    "    'Feature_4': np.random.choice(['A', 'B', \" \"], size=100, p=[0.3, 0.61, 0.09])\n",
    "})\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MpVifEN6EwD8"
   },
   "source": [
    "# Section 1: Visualizing Missing Data\n",
    "\n",
    "Before handling missing data, it's essential to understand its extent and distribution. Visualization tools help us quickly identify patterns and the magnitude of missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KS2KSTV0Erw7"
   },
   "outputs": [],
   "source": [
    "print(\"Dataset Preview:\")\n",
    "print(data.head())\n",
    "print(\"len: \", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ZPquI1hFpfn"
   },
   "outputs": [],
   "source": [
    "# count the null values in each feature\n",
    "print(data.isnull().sum())\n",
    "\n",
    "print(\"\\nBe careful with categorical variables!\")\n",
    "data = data.replace(\" \", np.nan)\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PQ7VsqmmFyEr"
   },
   "outputs": [],
   "source": [
    "feature_1_count = (data['Feature_1'].isnull().sum() / len(data)) * 100\n",
    "print(\"Percentage of null values in the first feature: \", feature_1_count, \"%\")\n",
    "\n",
    "feature_2_count = (data['Feature_2'].isnull().sum() / len(data)) * 100\n",
    "print(\"Percentage of null values in the second feature: \", feature_2_count, \"%\")\n",
    "\n",
    "feature_3_count = (data['Feature_3'].isnull().sum() / len(data)) * 100\n",
    "print(\"Percentage of null values in the third feature: \", feature_3_count, \"%\")\n",
    "\n",
    "feature_4_count = (data['Feature_4'].isnull().sum() / len(data)) * 100\n",
    "print(\"Percentage of null values in the fourth feature: \", feature_4_count, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y8-X2gRvEw2y"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(data.isnull(), cbar=False, cmap='viridis', yticklabels=False)\n",
    "plt.title(\"Heatmap of Missing Data\")\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Observations\")\n",
    "plt.show()  # yellow indicates a missing value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dUfCBET6E1mQ"
   },
   "source": [
    "# Section 2: Handling Missing Data\n",
    "\n",
    "Handling missing data involves selecting appropriate strategies based on the nature of the data and the problem at hand. Below, we'll explore common methods such as:\n",
    "- **Deletion:** Removing rows or columns with missing values.\n",
    "- **Imputation:** Filling in missing values using statistical or machine learning methods.\n",
    "\n",
    "Each feature in our dataset will be analyzed individually for tailored handling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CwwAAW2sLE6t"
   },
   "source": [
    "## Feature_1: Row-wise Deletion vs. Mean Imputation\n",
    "\n",
    "*Feature_1* contains a small number of null values, which can be addressed by either **removing the rows with missing data** or **imputing the missing values** using an appropriate strategy (mean, median for numerical variables).\n",
    "\n",
    "One common method is mean imputation, where the missing values are replaced with the average of the observed values in the feature. This approach is simple and fast, but it may not always be the best choice if the data has outliers or is highly skewed, as it can distort the distribution of the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hPbnbx-dLUAy"
   },
   "outputs": [],
   "source": [
    "# Row-wise deletion\n",
    "example_data_1 = data.copy()\n",
    "example_data_1 = example_data_1.dropna(subset=['Feature_1'])\n",
    "\n",
    "print(\"\\nAfter Row Deletion:\")\n",
    "print(example_data_1['Feature_1'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J7iu3cQRLVrm"
   },
   "outputs": [],
   "source": [
    "# Mean Imputation\n",
    "example_data_1_mean = data.copy()\n",
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "example_data_1_mean['Feature_1'] = mean_imputer.fit_transform(example_data_1_mean[['Feature_1']])\n",
    "\n",
    "print(\"\\nAfter Mean Imputation:\")\n",
    "print(example_data_1_mean['Feature_1'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ud7VkagqLWRX"
   },
   "outputs": [],
   "source": [
    "# Simpler Median Imputation\n",
    "example_data_1_median = data.copy()\n",
    "median = example_data_1_median['Feature_1'].dropna().median()\n",
    "example_data_1_median['Feature_1'] = example_data_1_median[['Feature_1']].fillna(median)\n",
    "\n",
    "print(\"\\nAfter Median Imputation:\")\n",
    "print(example_data_1_median['Feature_1'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Original vs Median distribution\n",
    "print(data['Feature_1'].describe())\n",
    "print(example_data_1_median['Feature_1'].describe())"
   ],
   "metadata": {
    "id": "5j7uBL3XQ8Ii"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qlFwrO3kJmQP"
   },
   "source": [
    "## Feature_2: KNN Imputation\n",
    "\n",
    "*Feature_2* contains 24% null values, making it advisable to apply **more advanced imputation techniques** to handle the missing data effectively:\n",
    "- **KNN Imputation**: Leveraging the k-nearest neighbors algorithm to estimate missing values based on the similarity of other observations. This approach can capture relationships between features and may provide better estimates, especially if the categories are not uniformly distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fd5EST5EIxee"
   },
   "outputs": [],
   "source": [
    "print(\"\\nHandling Feature_2:\")\n",
    "\n",
    "example_data_2 = data.copy()\n",
    "knn_imputer = KNNImputer(n_neighbors=3)\n",
    "example_data_2['Feature_2'] = knn_imputer.fit_transform(example_data_2[['Feature_2']])\n",
    "\n",
    "print(\"\\nAfter KNN Imputation:\")\n",
    "print(example_data_2['Feature_2'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Original vs Knn Imputation distribution\n",
    "print(data['Feature_2'].describe())\n",
    "print(example_data_2['Feature_2'].describe())"
   ],
   "metadata": {
    "id": "zCWCPdKQRgwd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MpgBaQMqLiEU"
   },
   "source": [
    "## Feature_3: Column Deletion\n",
    "\n",
    "\n",
    "*Feature_3* contains 80% null values, leaving limited useful information. It is more practical to drop this feature altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8OypWyBWE290"
   },
   "outputs": [],
   "source": [
    "example_data_3 = data.copy()\n",
    "example_data_3 = example_data_3.drop(columns=['Feature_3'])\n",
    "\n",
    "print(\"\\nDataset after dropping Feature_3:\")\n",
    "print(example_data_3.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKTP6cLXMwHB"
   },
   "source": [
    "## Feature_4: Mode Imputation\n",
    "\n",
    "*Feature_4* is a categorical variable with approximately 9% missing values. Since the proportion of missing data is relatively small, it can be efficiently imputed using straightforward methods. Two commonly used approaches are:\n",
    "- **Mode Imputation**: Replacing missing values with the most frequently occurring category in the data. This method is simple and effective for categorical features with a small proportion of missing data.\n",
    "- **KNN Imputation**: Leveraging the k-nearest neighbors algorithm to estimate missing values based on the similarity of other observations. This approach can capture relationships between features and may provide better estimates, especially if the categories are not uniformly distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B4SWqwXbM6GE"
   },
   "outputs": [],
   "source": [
    "example_data_4 = data.copy()\n",
    "\n",
    "# Initialize the SimpleImputer with most_frequent strategy\n",
    "mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "mode_imputed_feature = pd.DataFrame(mode_imputer.fit_transform(example_data_4[['Feature_4']]))\n",
    "example_data_4['Feature_4'] = mode_imputed_feature\n",
    "\n",
    "print(\"\\nAfter Mode Imputation:\")\n",
    "print(example_data_4['Feature_4'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIkCUlJyFH1M"
   },
   "source": [
    "# Section 4: Exercises\n",
    "\n",
    "Now that we've covered the basics, it's your turn to practice! Complete the following exercises to solidify your understanding of handling missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9H5b9tX4FUwg"
   },
   "outputs": [],
   "source": [
    "# Exercise 1: Check for Missing Values\n",
    "\n",
    "# Load the titanic dataset.\n",
    "# Identify which features contain missing values and determine how many missing values each feature has.\n",
    "# Visualize the missing values using a heatmap.\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "titanic = sns.load_dataset(\"titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Exercise 2: Mean Imputation\n",
    "\n",
    "# Load the titanic dataset.\n",
    "# Check if there are any missing values in the dataset.\n",
    "# Apply mean imputation to fill the missing values in all features.\n",
    "# Verify that there are no more missing values after imputation.\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "titanic = sns.load_dataset(\"titanic\")"
   ],
   "metadata": {
    "id": "pOnx2ojVVmKU"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Exercise 3: KNN Imputation\n",
    "\n",
    "# Load the titanic dataset.\n",
    "# Check if there are any missing values in the dataset.\n",
    "# Apply KNN imputation to fill the missing values in all features.\n",
    "# Verify that there are no more missing values after imputation.\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "titanic = sns.load_dataset(\"titanic\")"
   ],
   "metadata": {
    "id": "rLzp8pjYV_MG"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Exercise 4:\n",
    "# A dataset tracks students' exam scores and whether they passed the course.\n",
    "# Some values are missing, but we can infer them logically:\n",
    "#\n",
    "# - If a student \"Passed Course\" (Yes), their Exam Score must be above a passing threshold.\n",
    "# - If a student \"Did Not Pass\" (No), their Exam Score must be below the threshold.\n",
    "# - If an Exam Score is given but \"Passed Course\" is missing, we can determine it based on the score.\n",
    "#\n",
    "# Tasks:\n",
    "# 1. Identify which missing values can be logically inferred.\n",
    "# 2. Implement a function to fill missing values using rule-based logic instead of statistics.\n",
    "# 3. Handle edge cases where the rule may not be sufficient.\n",
    "#\n",
    "# Example dataset:\n",
    "# students = [\n",
    "#     {\"name\": \"Alice\", \"exam_score\": 85, \"passed\": \"Yes\"},\n",
    "#     {\"name\": \"Bob\", \"exam_score\": 40, \"passed\": \"No\"},\n",
    "#     {\"name\": \"Charlie\", \"exam_score\": None, \"passed\": \"Yes\"},\n",
    "#     {\"name\": \"David\", \"exam_score\": 70, \"passed\": None},\n",
    "#     {\"name\": \"Eve\", \"exam_score\": None, \"passed\": \"No\"}\n",
    "# ]"
   ],
   "metadata": {
    "id": "CgK0UpijHKEH"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
